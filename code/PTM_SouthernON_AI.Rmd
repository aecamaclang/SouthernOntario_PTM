---
title: "PTM_SouthernON_AI"
author: "AranyaIyer"
date: "2023-03-10" ####LAST UPDATED  -> December 4th, 2023 (3% PV, rounded benefits)
output: html_document
---

This is the document to be used for PTM Southern Ontario analysis. It has all the seperate codes in one Markdown file to streamline for efficiency. Only the final codes should be put and updated here. 

Scripts are originally written by Abbey C. and are then modified by Aranya I. The original scripts can be pulled from Abbey's github - https://github.com/aecamaclang/PTM_3-point-est

Step 1: Import the data 

This script reads individual expert estimates from multiple .csv files, compiles them into a single table, and reorganizes the table into a tidy version. It requires that the individual expert tables contain the same number of rows and columns, are saved as .csv file in a subfolder within the working directory, and no other .csv files are in the same subfolder.
```{r}
#+ warning = FALSE, message = FALSE
# Load packages
library(here)
library(tidyverse)
library(naniar)

# Specify paths to subfolders within current working directory
input <- here("analysis", "data", "raw", "benefits","Dec042023") # where .csv files of benefit estimates are saved
derived <- here("analysis", "data","Dec042023") # where compiled data tables should be saved
results <- here("analysis", "results","Dec042023") # where results of analysis should be saved


#' Read in the individual tables of expert estimates and combine.  
#' NOTE to maintain confidentiality, only sample tables are provided
nstrat <- 15 # number of strategies (including combinations, but excluding baseline)
ngroups <- 16 # number of ecological groups
numexp <- 13 # number of experts

numcols <- (nstrat+1+2) # number of cols to read in (one per strategy + 1 for Baseline + 2 for row header names)
numrows <- (ngroups+1)*3 # number of rows to read in (3 rows [Best, Low, High] per Ecol group and the example )

skiplines <- 20 # number of header rows to skip 

# Combine .csv files into single data frame

##AI -> convert excel workbook to csv -> only need to do this once! After that, it can be commented out. 
# library("rio")
# xls <- list.files(path = paste(input, "/", sep=""),
#                   pattern = "*xlsx",
#                   full.names = T)
# created <- mapply(convert, xls, gsub("xlsx", "csv", xls))

# read in the files 
files <- list.files(path = paste(input, "/", sep=""),
                    pattern = "*.csv", 
                    full.names = T)
listcsv <- lapply(files, 
                  function(x) read.csv(x, 
                                       skip = skiplines, 
                                       header = F, 
                                       nrows = numrows, 
                                       as.is = T))
rawdata <- do.call("rbind", listcsv) ##Currently have 663 obs for 19 variables 

# Check that all rows have been read
checkrows <- nrow(rawdata)
if (checkrows != numrows*numexp) {
  warning("Unexpected number of rows in the combined table")
}

rawdata <- rawdata[,1:numcols] # exclude 'Notes' column

# Add column names
names(rawdata) <- c("Ecological.Group", 
                    "Estimate", 
                    "Baseline", 
                    paste(rep("S", times = nstrat), 
                          1:nstrat, 
                          sep = "")) 

# Add new column for Expert ID
tempvec <- c()

for (i in 1:numexp) {
  tempvec <- c(tempvec, rep(i, times = (ngroups+1)*3))
}

rawdata <- rawdata %>% 
  add_column(Expert = tempvec, .before = "Ecological.Group")

#' Format table
data <- rawdata %>% 
  mutate(Ecological.Group = ifelse(Ecological.Group == "", NA, Ecological.Group)) %>% # changes blank rows to NA
  fill(Ecological.Group) %>% # fills NA rows with Ecological Group name
  filter(!grepl("example", Ecological.Group)) # remove 'example' rows 

# Standardize column/row names (if needed - also useful for plotting)
list(unique(data$Ecological.Group))
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Alvar/Rock barren/Shield") == 1)] <- "Alvar species"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Artificial/Man-made Structures") == 1)] <- "Artificial structure dependent species"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Bats") == 1)] <- "Bats"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Lake") == 1)] <- "Ciscos"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Mussels") == 1)] <- "Mussels"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Oak Savannah") == 1)] <- "Oak savannah species"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Riparian") == 1)] <- "Riparian species"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Sandy") == 1)] <- "Sandy species"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Snakes and Lizard") == 1)] <- "Snakes and lizard"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Turtles") == 1)] <- "Turtles"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Wetland") == 1)] <- "Wetland species"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Working Landscapes") == 1)] <- "Working landscapes species"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Naturalized Open habitats") == 1)] <- "Naturalized open habitat species"


#Have to leave these two seperate - forest one getting messed up 
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Mixed Forest") == 1)] <- "Mixed"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Forest") == 1)] <- "Forest species"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Mixed") == 1)] <- "Mixed forest species"
data$Ecological.Group[which(str_detect(data$Ecological.Group, "Riverine") == 1)] <- "Riverine species"


data$Estimate[which(str_detect(data$Estimate, "High") == 1)] <- "High"
data$Estimate[which(str_detect(data$Estimate, "Low") == 1)] <- "Low"

# Replace X's and blanks with NA
na_strings <- c("X", "X ", "x", "x ")
clean <- data %>%
  replace_with_na_all(condition = ~.x %in% na_strings) %>%
  replace_with_na_all(condition = ~.x == "")

# Replace B's with value for baseline estimates from same row 

for (i in 1:(numexp*ngroups*3)) {
  temp <- which(data[i,] == "B" | data[i,] == "b") #wherever people have put B or B, replace with the value in column 4 of that same row
  clean[i,temp] <- data[i,4]
}

write.csv(clean, file = paste(derived, "/Estimates_clean.csv", sep = ""), row.names = FALSE) ##Currently have 624 obs for 19 variables (16 species groups * 3 estimates * 13 experts = 624)

#' Convert to tidy version
long <-
  gather(clean,
         key = Strategy,
         value = Value,
         Baseline:S15
  )

write_csv(long, file = paste(derived, "/Estimates_tidy.csv", sep = "")) ##Currently have 9984 obs for 5 variables (16 species groups * 3 estimates * 13 experts = 624*16 (including baseline)=9984)
# head(long)

#' Convert to wide format

grp.levels <- unique(long$Ecological.Group)

long <- na.omit(long) #removes all the ones with NAs (down to 5997 obs)
long$Value <- as.numeric(long$Value)

tempvec <- paste(long$Strategy, long$Estimate, sep = ".")
long <- add_column(long, Strat.Est = tempvec, .before = "Value")
est.levels <- unique(long$Strat.Est)

long.sub <- long[,c(1,2,5,6)]
wide <- spread(long.sub, 
               key = Strat.Est, 
               value = Value)
wide$Ecological.Group <- factor(wide$Ecological.Group, levels = grp.levels) 

wide <- wide[, c("Expert", "Ecological.Group", est.levels)] # Reorder columns by Strategy
wide <- with(wide, wide[order(Expert, Ecological.Group),]) # Reorder rows by Ecological Group

write_csv(wide, file = paste(derived, "/Estimates_wide.csv", sep = "")) #Currently, we are at 131 obs for 50 variables -> #this is correct and most current. 

# head(wide)

#' Summarize the number of expert estimates
temp <- subset(long, Estimate == "Best")

strat.levels <- unique(temp$Strategy)
temp$Strategy <- factor(temp$Strategy,levels = strat.levels)

stgy.count <- table(temp$Ecological.Group, temp$Strategy)
stgy.count #should roughly align with your CostFeasCOUNTS_ON

write.csv(stgy.count, file = paste(results, "/estimatecounts.csv", sep = ""))
```

Step 1A: Plot the imported data [ONLY RUN IF YOU ARE GIVING BACK TO EXPERTS FOR REVIEW]

Based on *Boxplot_script.R* from Fraser River Estuary PTM project 
This script creates two plots for each Ecological Group:  
1) boxplots of the best guess, lowest, and highest estimates for each Strategy from all Experts;  
2) pointrange plots showing the best guess, lowest, and highest estimates of each Expert for each Strategy.  

```{r}
library(tidyverse)
library(cowplot)
library(gridExtra)
library(here)

# Specify paths to subfolders within current working (R project) directory
derived <- here("analysis", "data") # where compiled data tables are saved
results <- here("analysis", "results") # where results of analysis should be saved
figures <- here("analysis", "figures") # where plots should be saved -> AI: Original project did not have this, had to add in the folder for code to run

# Read in data
long <- read_csv(paste(derived,"/Estimates_tidy.csv", sep=""))

strat.levels <- unique(long$Strategy)
grp.levels <- unique(long$Ecological.Group)
expcode <- unique(long$Expert) 
est.levels <- c("Low", "Best", "High")

long$Strategy <- factor(long$Strategy, levels = strat.levels)
long$Estimate <- factor(long$Estimate, levels = est.levels)

long <- na.omit(long) #Currently at 4605 obs for 5 variables 

#' ## Boxplots
#' Plot group estimates as boxplots
#+ message = FALSE, warning = FALSE
for (j in seq_along(expcode)) {
  
  grp.list <- list()
  
  # If you do not need to highlight each individual response, run the inside loop (below) only to get a single file
  for (i in seq_along(grp.levels)) { 
    
    temp.grpdata <- subset(long, Ecological.Group == grp.levels[i])
    
    temp.plot <-
      ggplot(temp.grpdata, aes(x = Estimate, # for each Ecological group, plot Estimate Type on x-axis 
                               y = Value, # and Value on y-axis, 
                               fill = Estimate) # and colour the boxplots by estimate type
      ) + 
      # geom_violin() +  # option to add a violin plot around the boxplot - if doing so, reduce boxplot width in next line
      geom_boxplot(width=0.4) + 
      geom_point(data = subset(temp.grpdata, Expert == expcode[j]), # plot expert [j]'s estimates as blue points 
                 aes(x = Estimate, y = Value),
                 color = 'blue'
      ) + # include the geom_point option only if you want to highlight individual expert responses
      theme_cowplot() +  # use the minimalist theme "cowplot" 
      theme(plot.margin = unit(c(1.5, 1, 1.5, 1), "cm"), # adjust margins around the outside of the plot (T, R, B, L)
            panel.spacing = unit(1, "lines"), # adjust margins and between panels of the plot (spacing of 1)
            axis.title.y = element_text(margin = margin(t = 0, 
                                                        r = 10,
                                                        b = 0,
                                                        l = 0) # adjust space bet. y-axis numbers and y-axis label
            ),
            plot.caption = element_text(size = 10, hjust = 0)
      ) + 
      facet_wrap( ~ Strategy, nrow = 3) +  # create a separate panel of estimates for each management strategy
      scale_x_discrete(name = "",
                       breaks = c("Low", "Best", "High"),
                       labels = c("L", "B", "H") # Give the x-axis variables shortened labels
      ) + 
      scale_fill_manual(values = c("white", "gray80", "white"), # Assign colours to each type of estimate
                        guide = "none" # remove legend
      ) + 
      labs(x = "", 
           y = "Probability of persistence (%)", 
           title = paste(grp.levels[i]),
           caption = str_wrap(paste0(
             "Figure ", i, ". Boxplots summarizing the distribution of the lowest (L), best guess (B), and highest (H) expert 
             estimates of the probability of persistence of ", grp.levels[i], " under the Baseline scenario and each of the 
             management strategies (S1 - S15). The thick horizontal lines indicate the median estimate, while the surrounding 
             box shows the interquartile range. Any outliers are shown as points beyond the plot whiskers. Your individual 
             estimates are shown in blue."), 150)
      ) +
      ylim(0, 100) # set the y-axis limits from 0-100
    
    grp.list[[i]] <- temp.plot
    
  }
  
  # Save all plots as a single .pdf: 
  plot1 <- marrangeGrob(grp.list, nrow = 1, ncol = 1, top = NULL) # one plot per page
  ggsave(
    # filename = "All_boxplot.pdf", # use instead of below if generating a single file with no highlighting
    filename = paste0("exp", expcode[j], "_boxplot.pdf", sep=''),
    plot1, 
    path = figures, 
    width = 11, height = 8.5, units = "in")
  
}

# print(plot1)

#' ## Pointrange plots
#' Plots each expert estimate separately (x-axis = Expert, y-axis point = Best guess, range = low->high)
#+ message = FALSE, warning = FALSE
# Rearrange table so estimates for each ecol group-strategy are on the same row
wide <- spread(long, key = Estimate, value = Value)
wide$Expert <- as.factor(wide$Expert)

# Create plots
for (j in seq_along(expcode)) {
  
  grp.list <- list()
  
  # If you do not need to highlight each individual response, run the inside loop (below) only to get a single file
  for (i in seq_along(grp.levels)) {
    
    temp.expdata <- subset(wide, Ecological.Group == grp.levels[i])
    temp.expdata <- mutate(temp.expdata, expi = ifelse(Expert == expcode[j], T, F)) # use only if highlighting individual expert responses
    
    temp.plot2 <-
      ggplot(temp.expdata, aes(x = Expert, # using the data Ecological group, plot Experts on X-axis
                               y = Best, # and corresponding standardized estimates on y-axis
                               color = expi, # use this only if highlighting individual expert responses
      )
      ) +  
      geom_pointrange(aes(ymin = Low, ymax = High)) +
      theme_cowplot() +  
      theme(plot.margin = unit(c(1.5, 1, 1.5, 1), "cm"), # adjust margins around the outside of the plot
            panel.spacing = unit(1, "lines"), # adjust margins and between panels of the plot (spacing of 1)
            axis.title.y = element_text(margin = margin(t = 0,
                                                        r = 10,
                                                        b = 0,
                                                        l = 0)), # adjust space between y-axis numbers and y-axis label
            axis.text.x = element_text(size=10),
            legend.justification=c(1,0), legend.position=c(0.98,-0.05), # re-positions legend box
            plot.caption = element_text(size = 10, hjust = 0)
      ) +  
      scale_color_manual(values = c("grey", "blue"), guide = "none") + # only needed if highlighting individual expert responses
      facet_wrap( ~ Strategy, nrow = 3) +  # create a separate panel of estimates for each management strategy
      labs(x = "Experts",
           y = "Probability of persistence (%)",
           title = paste(grp.levels[i]),
           caption = str_wrap(paste0(
             "Figure ", i, ". Plots of each expert estimate of the probability of persistence of ", grp.levels[i], 
             " under the Baseline scenario and each of the management strategies (S1 - S15). Each point indicates 
             the best guess of one expert. Your individual estimates are plotted in blue."), 150)
      ) +
      ylim(0, 100) # set the y-axis limits from 0-100
    
    grp.list[[i]] <- temp.plot2
  }
  
  # Save all plots as a single .pdf: 
  plot2 <- marrangeGrob(grp.list, nrow = 1, ncol = 1, top = NULL) # one plot per page
  ggsave(
    # filename = "All_pointrange.pdf", # if plotting all estimates without highlighting
    filename = paste0("exp", expcode[j], "_pointrange.pdf", sep=''), # if highlighting individual expert estimates
    plot2, 
    path = figures, 
    width = 11, height = 8.5, units = "in"
  )
  
}

print(temp.plot2)
```

Step 2: Aggregate/average the estimates across the experts 

This code 
a) calculates benefits of each strategy (strategy - baseline) for each ecological group,  
b) aggregates (averages) across experts, and  
c) calculates expected performance (probability of persistence) under each strategy based on the aggregated estimates.  
   
Based on first part of Step 2 section of 1_Cost-Effectiveness.R code from the Fraser River Estuary PTM project.  
This script uses **Estimates_wide.csv** from *import.R*.
If some of the expert estimates for a given ecological group are based on only a subset of species in that group, this estimate need to be weighted accordingly. To do this, you need  
1) a .csv file *EcolGroupsList.csv* with ecological groups in columns and the list of species for each group in rows, and   
2) a .csv file *SpecialCases.csv* listing only the estimates (from which expert, and for which ecol group and strategy) that require different weighting, along with the number of species in that group that the estimate is based on.  

```{r}
library(tidyverse)
library(here)

# Specify paths to subfolders within current working directory
input <- here("analysis", "data", "raw") # where unchanging things are 
derived <- here("analysis", "data","Dec042023") # where compiled data tables should be saved
results <- here("analysis", "results","Dec042023") # where results of analysis should be saved

# Specify how estimates should be aggregated - this should be based on the
# experts' comments, i.e., whether all species in the ecological group were
# considered in making the estimate, or only a subset of species. Select:  
# (1) if weighting each expert estimate based on the number of species in each group that they scored,  
# (0) if assuming all species in the group were considered in the estimate
wt.by.numspp <- 1 ##AI: modifying this for new script 

# Read in and prepare data
long <- read_csv(paste0(derived, "/Estimates_tidy.csv")) ##Current counts are 9984 obs for 5 variables (16 groups *3 estimates * 16 strategies (includes baseline)*13 experts = 9984)
grp.levels <- unique(long$Ecological.Group)

wide <- read_csv(paste0(derived, "/Estimates_wide.csv"))
wide$Expert <- as_factor(wide$Expert)
wide$Ecological.Group <- factor(wide$Ecological.Group, levels = grp.levels)

#' Calculate benefit
# Subtract baseline performance from strategy performance
baseline <- wide[3:5]
strategies <- wide[6:ncol(wide)]  
benefit <- strategies - as.matrix(baseline) #only the benefit of the strategy, nothing else 

benefit[benefit < 0] <- 0 # if there are any logical errors that result in negative values #AI: Quick check revealed no problem in this 

# Add row labels back to the tables
benefit <- cbind(wide[,1:2], benefit) 
baseline <- cbind(wide[,1:2], baseline)

#' Aggregate (weighted average) benefit and the baseline estimates for each ecol group x strategy

###ONLY RUNNING when loop = 1, for whole loop - see bottom. 
# Re-organize benefits table to make it easier to weight estimates
benefit.long <- gather(benefit, 
                       key = Est.type, 
                       value = Value, 
                       -c(1:2)) %>%
  separate(., 
           Est.type, 
           c("Strategy", "Estimate"), 
           sep = "[.]", 
           remove = TRUE)

strat.levels <- c("Baseline", unique(benefit.long$Strategy))
benefit.long$Strategy <- factor(benefit.long$Strategy, levels = strat.levels)
benefit.long$Estimate <- as_factor(benefit.long$Estimate) #Currently at 5895 for 5 variables 

benefit.wide <- spread(benefit.long, 
                       key=Estimate, 
                       value = Value) #Currently at 1965 for 6 variables 

# Get number of species in each group and number of species scored by each expert for each strategy
grplist <- read_csv(paste0(input, "/EcolGroupsList.csv")) 
numspp <- apply(grplist, MARGIN = 2, FUN = function(x) length(x[!is.na(x)]) )
grpwts <- data.frame(Ecological.Group=names(numspp), numspp) 
grpwts$Ecological.Group <- factor(grpwts$Ecological.Group, levels = unique(names(numspp)))

spcases <- read_csv(paste0(derived, "/SpecialCases.csv")) 
spcases$Strategy <- factor(spcases$Strategy, levels = levels(benefit.wide$Strategy))
spcases$Expert <- factor(spcases$Expert, levels = levels(benefit.wide$Expert))
spcases$`Ecological Group`<- factor(spcases$`Ecological Group`, levels = levels(benefit.wide$Ecological.Group))
names(spcases)[which(str_detect(names(spcases), "Ecological Group")==1)] <- "Ecological.Group"  

# Join tables to calculate weights for each estimate
benefit.joined <- left_join(benefit.wide, spcases, # new column for number of species that estimate is based on
                            by=c("Expert", "Ecological.Group", "Strategy")) %>% 
  left_join(., grpwts, by = "Ecological.Group") # total number of species in ecol. group

fullwts.idx <- which(is.na(benefit.joined$NumSppScored)) # NOTE: NAs indicate estimates that are based on all species in the ecol group (i.e., full weights)
benefit.joined$NumSppScored[fullwts.idx] <- benefit.joined$numspp[fullwts.idx] # fills in the column with the total number of species

fullwts <- aggregate(benefit.joined$NumSppScored, # sums the number of spp scored across all experts and all strategies 
                     by = list(Ecological.Group = benefit.joined$Ecological.Group, 
                               Strategy = benefit.joined$Strategy), 
                     FUN = sum, na.rm = TRUE)

benefit.joined <- benefit.joined %>%
  left_join(., fullwts, by = c("Ecological.Group", "Strategy")) %>% # adds a column with values (sums) from the aggregate() function above
  mutate(Wts = NumSppScored/x) %>% # calculate the weights to assign (NOTE: x is the sum from above)
  mutate(Wt.Best = Best*Wts,  # applies the weights to the benefit values
         Wt.Low = Low*Wts, 
         Wt.High = High*Wts)

# Aggregate (sum) the weighted estimates and re-organize table for calculating performance -> AI: average benefit for species group across all experts 
benefit.avg <- aggregate(benefit.joined[,11:13], 
                         by = list(Ecological.Group = benefit.joined$Ecological.Group, 
                                   Strategy = benefit.joined$Strategy), 
                         FUN = sum, na.rm = TRUE) %>%
  gather(., key = "Est.Type", 
         value = "Wt.Avg", 
         Wt.Best, Wt.Low, Wt.High) #720 rows because 16 species groups * 15 strategies *3 estimates = 720

benefit.avg$Est.Type <- as_factor(benefit.avg$Est.Type)

benefit.avg <- benefit.avg %>%
  arrange(Ecological.Group, Strategy, Est.Type) %>%
  unite(., col = "Estimate", 
        c("Est.Type", "Strategy"), 
        sep = "_", remove = TRUE)

benefit.avg$Estimate <- as_factor(benefit.avg$Estimate)

benefit.avg <- benefit.avg %>% #AI: NOTE HERE that you are comparing strategy best with baseline best, strategy high with baseline high, and strategy low with baseline low (which is why values for high might be lower than values for best)
  spread(., Estimate, Wt.Avg)

# Prepare the baseline estimates table
baseline <- baseline %>%
  rename(Best = Baseline.Best, Low = Baseline.Low, High = Baseline.High) %>%
  add_column(Strategy = rep("Baseline", nrow(baseline)), 
             .before = "Best")
baseline$Strategy <- factor(baseline$Strategy, levels = strat.levels)

# Calculate weights as for benefits (above) - ie., weighted average for baseline values 
baseline.joined <- left_join(baseline, spcases, 
                             by = c("Expert", "Ecological.Group", "Strategy")) %>%
  left_join(., grpwts, by = "Ecological.Group")

base.fullwts.idx <- which(is.na(baseline.joined$NumSppScored))
baseline.joined$NumSppScored[base.fullwts.idx] <- baseline.joined$numspp[base.fullwts.idx]

base.fullwts <- aggregate(baseline.joined$NumSppScored, 
                          by = list(Ecological.Group = baseline.joined$Ecological.Group, 
                                    Strategy = baseline.joined$Strategy), 
                          FUN = sum, na.rm = TRUE)
baseline.joined <- baseline.joined %>%
  left_join(., base.fullwts, by = c("Ecological.Group", "Strategy")) %>%
  mutate(Wts = NumSppScored/x) %>%
  mutate(Wt.Best_Baseline = Best*Wts,
         Wt.Low_Baseline = Low*Wts,
         Wt.High_Baseline = High*Wts)

# baseline.joined <- subset(baseline.joined, select = -Strategy.1)

baseline.avg <- aggregate(baseline.joined[,11:13], 
                          by = list(Ecological.Group = baseline.joined$Ecological.Group, 
                                    Strategy = baseline.joined$Strategy), 
                          FUN = sum, na.rm = TRUE) %>%
  select(., -Strategy)

###CLOSING line on when loop =1 

write_csv(benefit.avg, paste0(results, "/Estimates_avg_benefits.csv"))
write_csv(baseline.avg, paste0(results, "/Estimates_avg_baseline.csv"))


##########Checking to see if the combination weighted benefits are higher than individual strategies
#####################################################################################################
results <- here("analysis", "results","June282023") # where results of analysis should be saved
benefit.avg <- read.csv(paste0(results, "/Estimates_avg_benefits.csv"))
benefit.best_est <- benefit.avg %>%
  select(matches("Best|Group")) ##Only best estimates 
benefit.best_est.long <- benefit.best_est%>%pivot_longer(!Ecological.Group) ##seems right that the highest for each is S15
benefit.best_est.longlist <- benefit.best_est.long %>% group_by(Ecological.Group) %>% summarise(value = max(value))
benefit.best_est.longlist <- merge(benefit.best_est.longlist,benefit.best_est.long, by=c("Ecological.Group","value")) #Sandy NOT flagged anymore! (Apr-13)


benefit.high_est <- benefit.avg %>%
  select(matches("High|Group")) ##Only high estimates 
benefit.high_est.long <- benefit.high_est%>%pivot_longer(!Ecological.Group) ##seems right that the highest for each is S15
benefit.high_est.longlist <- benefit.high_est.long %>% group_by(Ecological.Group) %>% summarise(value = max(value))
benefit.high_est.longlist <- merge(benefit.high_est.longlist,benefit.high_est.long, by=c("Ecological.Group","value")) 
##NO FLAG! 

benefit.low_est <- benefit.avg %>%
  select(matches("Low|Group")) ##Only low estimates 
benefit.low_est.long <- benefit.low_est%>%pivot_longer(!Ecological.Group) ##seems right that the highest for each is S15
benefit.low_est.longlist <- benefit.low_est.long %>% group_by(Ecological.Group) %>% summarise(value = max(value))
benefit.low_est.longlist <- merge(benefit.low_est.longlist,benefit.low_est.long, by=c("Ecological.Group","value")) #NO Flag!! 

###################################################################################################
###################################################################################################


#' Calculate averaged performance (probability of persistence)
# Add averaged benefit estimates to the (averaged) baseline
persistence <- benefit.avg[,2:ncol(benefit.avg)] + as.matrix(baseline.avg[,2:ncol(baseline.avg)]) #average baseline + benefits 
persistence <- cbind(baseline.avg, persistence) #add in labels

write_csv(persistence, paste0(results, "/Estimates_avg_persistence.csv"))

#' Weight benefits by number of species in group (multiply) for calculating CE scores <- #AI: this is only if you did the weighted species 
grpwtd_ben <- benefit.avg[,2:ncol(benefit.avg)]*numspp
grpwtd_ben <- cbind(benefit.avg[,1], grpwtd_ben)
names(grpwtd_ben)[1] <- "Ecological.Group"

write_csv(grpwtd_ben, paste0(results, "/Estimates_avg_benefits_groupwtd.csv"))


##########Checking to see if the combination weighted benefits are higher than individual strategies
###################################################################################################
###################################################################################################
results <- here("analysis", "results","June282023") # where results of analysis should be saved
pop_est <- read.csv(paste0(results, "/Estimates_avg_benefits_groupwtd.csv"))

pop.best_est <- pop_est %>%
  select(matches("Best|Group")) ##Only best estimates 
pop.best_est.long <- pop.best_est%>%pivot_longer(!Ecological.Group) ##seems right that the highest for each is S15
pop.best_est.longlist <- pop.best_est.long %>% group_by(Ecological.Group) %>% summarise(value = max(value))
pop.best_est.longlist <- merge(pop.best_est.longlist,pop.best_est.long, by=c("Ecological.Group","value")) #NONE flagged (Apr-13)


pop.high_est <- pop_est %>%
  select(matches("High|Group")) ##Only high estimates 
pop.high_est.long <- pop.high_est%>%pivot_longer(!Ecological.Group) ##seems right that the highest for each is S15
pop.high_est.longlist <- pop.high_est.long %>% group_by(Ecological.Group) %>% summarise(value = max(value))
pop.high_est.longlist <- merge(pop.high_est.longlist,pop.high_est.long, by=c("Ecological.Group","value")) ##SANDY NOT FLAGGED 

pop.low_est <- pop_est %>%
  select(matches("Low|Group")) ##Only high estimates 
pop.low_est.long <- pop.low_est%>%pivot_longer(!Ecological.Group) ##seems right that the lowest for each is S15
pop.low_est.longlist <- pop.low_est.long %>% group_by(Ecological.Group) %>% summarise(value = max(value))
pop.low_est.longlist <- merge(pop.low_est.longlist,pop.low_est.long, by=c("Ecological.Group","value"))##SANDY NOT FLAGGED  



###################################################################################################
######################################################################################################################


```


Step 2A: Plot the aggregated/averaged values - for expert eliciation, you DON'T NEED IT weighted by Cost-feas. For the final presentation of the report, you should probably have it weighted with feasibility. 

Creates pointrange plots of the aggregated estimates of probability of persistence (y-axis) for each strategy (x-axis) and for each ecological group (subplots).

It can be used to plot mean estimates that are either unweighted (**Estimates_avg_persistence.csv** from *aggregate.R*) or weighted by feasibility (**Expected_Performance.csv** from *expPerformance.R*)


The script below is from the one needed for expert elicitation (ie., not weighted by feasibility)
```{r}
library(tidyverse)
library(cowplot)
library(gridExtra)
library(here)
library(tidyr)

# Specify paths to subfolders within current working directory
results <- here("analysis", "results","June282023") # where results of analysis should be saved
figures <- here("analysis", "figures","June282023") # where plots should be saved

# Read in probability of persistence data
weighted <- 0 # (1) if values are weighted by feasibility, (0) if not #AI: for the first round of elicitation, you have to ensure that it is not weighted by feasibility 

if (weighted == 0) {
  est.file <- "/Estimates_avg_persistence" # unweighted
} else {
  if (weighted == 1) {
    est.file <- "/Expected_Performance" # feasibility weighted
  } else {
    stop("Must specify if estimates are weighted by feasibility (1) or not (0)")
  }
}

persistence <- read_csv(paste0(results, est.file, ".csv"))
grp.levels <- unique(persistence$Ecological.Group)
persistence$Ecological.Group <- factor(persistence$Ecological.Group, levels = grp.levels)

# Organize data into correct format for plotting
persistence.long <- persistence %>%
  gather(., key = "Estimate", value = "Value", -Ecological.Group) %>%
  separate(., Estimate, c("Est.Type", "Strategy"), sep = "[_]", remove = TRUE) %>%
  mutate(Strategy = factor(Strategy, levels = unique(Strategy)))

#Going to remove the rows where strategy is NA
persistence.long <- persistence.long %>% drop_na(Strategy)


plot.data <- persistence.long %>%
  spread(., 
         key = Est.Type, 
         value = Value)

strat.levels <- levels(plot.data$Strategy)

write_csv(plot.data, paste0(results, est.file, "_tidy.csv"))

baseline.data <- plot.data[which(plot.data$Strategy=="Baseline"),]
strategy.data <- plot.data[which(plot.data$Strategy!="Baseline"),]


#' Pointrange plots of averaged probability of persistence for each ecological group
# Plot aggregated estimate of probability of persistence under each strategy
temp.plot2 <- 
  ggplot(strategy.data, aes(x = Strategy, y = Wt.Best) ) +
  geom_pointrange(aes(ymin = Wt.Low, ymax = Wt.High)) +
  geom_hline(aes(yintercept = Wt.Best), baseline.data, colour = "blue") +
  geom_hline(aes(yintercept = Wt.Low), baseline.data, colour = "blue", lty = "dashed") +
  geom_hline(aes(yintercept = Wt.High), baseline.data, colour = "blue", lty = "dashed") +
  theme_cowplot() +  # minimalist theme from cowplot package
  theme(plot.margin = unit(c(1.5, 1, 1.5, 1), "cm"), # top, right, bottom and left margins around the plot area
        panel.spacing = unit(1, "lines"), # adjust margins and between panels of the plot (spacing of 1)
        axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)), # adjust space between y-axis numbers and y-axis label
        axis.text.x = element_text(size = 8, angle = 90, hjust = 0.5, vjust = 0.5),
        plot.caption = element_text(size =10, hjust = 0)
  ) +  facet_wrap( ~ Ecological.Group, nrow = 4, ncol = 4) +  # create a separate panel for each ecological group
  theme(strip.text = element_text(size=8))+
  # scale_x_discrete(breaks = strat.levels, labels = c("B", 1:16) ) +
  labs(x = "Strategies",
       y = "Probability of persistence (%)"
       # , title = "Mean estimates" 
       , caption = str_wrap("Figure 1. Estimated probability of persistence of each ecological group under each of the 
       management strategies (Best Guess = solid black dots, Lowest and- Highest estimates = black vertical lines),
       compared to the probability under the Baseline scenario (blue horizontal lines: Best Guess = solid lines, 
       Lowest and Highest Estimates = dashed lines). Values are based on expert estimates averaged over the 
       number of experts that provided estimates for the strategy and ecological group.", 100)) +  ylim(0, 100) 

# Save plot as pdf file
ggsave(filename=paste0(figures, est.file, "_plot.pdf"), 
       temp.plot2, 
       width = 8.5, height = 11, 
       units = "in")

print(temp.plot2)
```


Step 3: Calculate the CE_score 
This code calculates cost-effectiveness (CE) scores and ranks strategies by Benefit, Cost, and CE. Based on algorithm from Step 2 section of *1_Cost-Effectiveness.R* code from FRE PTM project, but using a different way to implement.  
   
Requires **Estimates_avg_benefits_groupwtd.csv** from *aggregate.R*, and a **CostFeas.csv** table of strategy cost and feasibility.  


```{r}
library(tidyverse)
library(here)

# Set scaling factor to get cost and benefits in roughly the same order of magnitude
a <- 10^6

# Specify paths to subfolders within current working directory
results <- here("analysis", "results","Dec042023") # where results of analysis should be saved

# Read in and prep data
ben.grpwtd <- read.csv(paste0(results, "/Estimates_avg_benefits_groupwtd.csv")) #AI: values will be into thousands here, esp for mixed forest and forest species bc it is just benefits multiplied by the number of species in the group 
costfeas <- read.csv(paste0(results, "/CostFeas.csv"))
costfeas <- costfeas[-1,] # Remove baseline values
costfeas$Strategy <- as_factor(costfeas$Strategy)
names(costfeas)[2] <- "Cost" # for ON PTM only - col 2 is the cost with 0% discount rate. Col 4 = 2%, Col5 = 3.5%
names(costfeas)[3] <- "Avg.Feas" # for ON PTM only

#' ### Calculate total benefit of each strategy
#' Sum benefits across all species/ecological groups
bestben <- ben.grpwtd[,-1] %>%
  t() %>%
  data.frame() %>%
  setNames(ben.grpwtd[,1]) %>%
  filter(grepl("Best", rownames(.))) #AI: Focuses only on the best benefits! 

bestben.sum <- data.frame(rowSums(bestben)) %>% #AI: takes the sum of all the rows (ie., sp groups) and creates a benefit value PER strategy
  mutate(Est.type = rownames(.)) %>%
  separate(Est.type, c("Estimate", "Strategy"), sep = "[_]", remove = TRUE) %>% #transfers row names to column 
  mutate(Estimate = NULL) %>%
  relocate(Strategy) %>%
  setNames(c("Strategy", "Benefit")) %>%
  mutate(Strategy = as_factor(Strategy))

# Save as R object for cost uncertainty analysis ##AI: New edit from Abbey April=13
saveRDS(bestben.sum, paste0(results, "/Benefits_total.rds")) 
  
##AI: This would be the place to try out different feasibility ideas and different cost ideas.

#' ### Calculate cost-effectiveness and rank strategies
#' CE = (Benefit * Feasibility)/Cost
CE_table <- full_join(bestben.sum, costfeas, by="Strategy")%>%
  mutate(Exp.Benefit = Benefit * Avg.Feas) %>% # weight benefits by feasibility -> benefits here is the BEST estimate, not the highest/lowest for the cost-effectivess! Using average benefits here instead of minimum 
  mutate(CE = (Exp.Benefit/Cost)*a) %>% # divide by cost then scale
  select(c("Strategy", "Benefit", "Cost", "Avg.Feas", "Exp.Benefit", "CE")) %>% #using average benefits and 0 discount 
  mutate(CE_rank = rank(-CE), #highest cost-benefit effectiveness GIVEN feasability 
         ExpBenefit_rank = rank(-Exp.Benefit), #highest benefit GIVEN feasability 
         Cost_rank = rank(Cost)) #based purely of lowest cost 

write.csv(CE_table, paste0(results, "/CE_Scores.csv"), row.names = FALSE)

#' Sample table
#+ echo = FALSE
# knitr::kable(CE_table, "simple", row.names = FALSE)

```

Step 4: 

This code:  
1) calculates expected benefit (benefit * feasibility)  
2) calculates expected performance based on weighted benefit estimates (this can be used with *plotAggregated.R in the final analysis after second round of expert elicitation)

Requires **Estimates_avg_benefits.csv** and **Estimates_avg_baseline.csv** from *aggregate.R*, and a **CostFeas.csv** table of strategy cost and feasibility

```{r}
library(tidyverse)
library(here)

# Specify paths to subfolders within current working directory
results <- here("analysis", "results","Dec042023") # where results of analysis should be saved

# Read in and prep data
benefit <- read.csv(paste0(results, "/Estimates_avg_benefits.csv"))
baseline <- read.csv(paste0(results, "/Estimates_avg_baseline.csv"))

costfeas <- read.csv(paste0(results, "/CostFeas.csv"))
costfeas <- costfeas[-1,] # Remove baseline values
costfeas$Strategy <- as_factor(costfeas$Strategy)

#' ### Calculate the expected benefit (benefit x feasibility) for ALL, not just the best benefits 
# Tidy data
long <- gather(benefit, 
               key = Est.type, 
               value = Value, 
               colnames(benefit)[2]:colnames(benefit)[ncol(benefit)]) %>%
  separate(Est.type, c("Estimate", "Strategy"), sep = "[_]", remove = FALSE) %>%
  mutate(Strategy = as_factor(Strategy), 
         Ecological.Group = as_factor(Ecological.Group),
         Est.type = as_factor(Est.type)) 

# Join with cost & feasibility table then weight benefit by feasibility -> AI: it changes between Avg. Feas and Min.Feas here - stick with avg. feas
joined <- left_join(long, costfeas, by = "Strategy") %>%
  mutate(Avg.ExpBen = Value * avg.Feas) 
#, Min.ExpBen = Value * min.Feas) # removing this because the newest CostFeas, I didn't include minFeas in table

# Reformat table and output results
exp.ben <- joined %>%
  select(c(Ecological.Group, Est.type, Avg.ExpBen)) %>% #AI: using only avg Feas here! 
  spread(key = Est.type, value = Avg.ExpBen)

write.csv(exp.ben, paste0(results, "/ExpBenefits.csv"), row.names = FALSE) #AI: IMPORTANT THING TO NOTE HERE IS THAT THIS IS NOT JUST BENEFIT. IT IS BENEFIT AND FEASIBILITY COMBINED. WHICH IS WHY WE HAVE THE difference in which strategies are preffered. 

#' Sample table:
#+ echo = FALSE
# knitr::kable(exp.ben, "simple")

#' ### Calculate expected performance (baseline probability of persistence + expected benefits)
# Join with baseline estimates to make sure the estimates line up correctly
joined.base <- left_join(baseline, exp.ben, by = "Ecological.Group") 

# Add expected benefit estimates to (averaged) baseline and get the expected performance
base.mat <- joined.base[,2:4]
perf.mat <- joined.base[,5:ncol(joined.base)] + as.matrix(base.mat)

exp.perf <- cbind(joined.base$Ecological.Group,base.mat,perf.mat)
names(exp.perf)[1] <- "Ecological.Group"

write.csv(exp.perf, paste0(results, "/ExpPerform_all.csv"), row.names = FALSE)

#' Sample table:
#+ echo = FALSE
# knitr::kable(exp.perf, "simple")

##########Checking to see if the combination weighted benefits are higher than individual strategies
###################################################################################################
###################################################################################################
results <- here("analysis", "results","June282023") # where results of analysis should be saved
exp.perf <- read.csv(paste0(results, "/ExpPerform_all.csv"))
perf.best_est <- exp.perf %>%
  select(matches("Best|Group")) ##Only best estimates 
perf.best_est.long <- perf.best_est%>%pivot_longer(!Ecological.Group) ##seems right that the highest for each is S15
perf.best_est.longlist <- perf.best_est.long %>% group_by(Ecological.Group) %>% summarise(value = max(value))
perf.best_est.longlist <- merge(perf.best_est.longlist,perf.best_est.long, by=c("Ecological.Group","value")) #Snakes and Lizzard - S9 (Wildlife crossing + Restoration), Forest (S11 - NbCS), Others- S15 

perf.high_est <- exp.perf %>%
  select(matches("High|Group")) ##Only high estimates 
perf.high_est.long <- perf.high_est%>%pivot_longer(!Ecological.Group) ##seems right that the highest for each is S15
perf.high_est.longlist <- perf.high_est.long %>% group_by(Ecological.Group) %>% summarise(value = max(value))
perf.high_est.longlist <- merge(perf.high_est.longlist,perf.high_est.long, by=c("Ecological.Group","value")) ##Turtles (S5 - Wildlife crossing), Agriculture + Forest + Alvar (S11 - NbCS)

perf.low_est <- exp.perf %>%
  select(matches("Low|Group")) ##Only high estimates 
perf.low_est.long <- perf.low_est%>%pivot_longer(!Ecological.Group) ##seems right that the lowest for each is S15
perf.low_est.longlist <- perf.low_est.long %>% group_by(Ecological.Group) %>% summarise(value = max(value))
perf.low_est.longlist <- merge(perf.low_est.longlist,perf.low_est.long, by=c("Ecological.Group","value"))##Turtles (S9 - Wildlife crossing + restoration), Forest + Sandy (s11 - NbCS)

###################################################################################################
######################################################################################################################


```

Step 5: 

Learn more about the exact optimisation code here since it is slightly different than the R code. 

This code performs the complementarity analysis using the consOpt R package developed by Nicolai Cryer <nkcryer@gmail.com> and updated by Abbey Camaclang with a number of bug fixes.  

Requires **ExpPerform_best.csv** from *expPerformance.R*, and the **CostFeas.csv** table of cost and feasibility for each strategy. Also requires a table **Combinations.csv** specifying which individual strategies are in the combination strategies.

NOTE: All strategies = includes combined strategies in list as well because internal code (1) does not double count costs, (2) uses the maximum benefit from any strategy as the "All strategy" benefit (does not consider synergy between the different strategies)

```{r}

myPaths <- .libPaths()

myPaths <- c(myPaths, "C:/Users/aiyer/OneDrive - WORLD WILDLIFE FUND CANADA/Documents/ON PTM/PTM_3-point-est-main/analysis/code/packages")

.libPaths(myPaths)  # add new path

#NOW you Need to physically go to Packages > Project Library > Matrix 

library(Matrix)
library("ompr")
library(consOpt)
library(tidyverse)
library(cowplot)
library(here)
library(dplyr)
library(ggplot2)

# Specify paths to subfolders within current working directory
input <- here("analysis", "data", "raw") # where raw data files are located
derived <- here("analysis", "data","Dec042023") # where compiled/summarized data are located
results_pre <- here("analysis", "results","Dec042023") # where results of previous analysis are saved 
results <- here("analysis", "results","Dec042023") # where results of analysis should be saved
figures <- here("analysis", "figures","Dec042023") # where plots should be saved

# Read in and prep data

combos <- read.csv(paste0(input, "/Combinations.csv"), header = TRUE) # list of individual strategies that make up each strategy (in columns). Should have a column for baseline and all strategies
exp.perf <- read.csv(paste0(results_pre, "/ExpPerform_all.csv")) #from previous step 
costfeas <- read.csv(paste0(results_pre, "/CostFeas.csv")) # estimated Cost and Feasibility for each Strategy (col 1), including Baseline
costs <- costfeas$Cost.0disc #changed here 
names(costs) <- costfeas$Strategy

#' Create expected performance matrix for complementarity analysis (optimization)
perf.transposed <- exp.perf[,-1] %>%
  t() %>%
  data.frame() %>%
  setNames(exp.perf[,1]) %>%
  mutate(Est.type = rownames(.)) %>%
  separate(Est.type, c("Estimate", "Strategy"), sep = "[_]", remove = TRUE) %>%
  relocate(Estimate, Strategy) %>%
  remove_rownames()

best <- perf.transposed %>%
  filter(grepl("Best", Estimate)) %>%
  mutate(Estimate = NULL) %>%
  column_to_rownames("Strategy")

####rounding - justification: experts provided to whole numbers 
best <- round(best, digits=0)

write.csv(best, paste0(results, "/ExpPerform_best.csv"), row.names = FALSE)

#' ### Find optimal strategies for most likely scenario (best guess estimates)  
#' Run the optimization routine across the default budgets and thresholds. 
#' For some sparse documentation, type ?Optimize  
#+ warning = FALSE, message = FALSE
results.best <- Optimize(benefits.matrix = best, 
                    cost.vector = costs, 
                    combo.strategies = combos
                    , thresholds = c(50.00,55.00,60.00) #do .00 not .01. #can technically put three thresholds 
                    )

write.csv(results.best, paste0(results, "/Complementarity_best.csv"), row.names = FALSE)


#' Sample output:
#+ echo = FALSE
# knitr::kable(results.best, "simple", row.names = FALSE)

#' Plot using plotting function included in the consOpt package
optcurve.best <- PlotResults(results.best)

#' OR create custom plot function (based on plotting function in the package):
#+ warning = FALSE, message = FALSE
library(viridis)

cols <- c("40" = "brown2", "50" = "goldenrod1", "60" = "darkolivegreen3", "70" = "darkmagenta")

PlotOptCurve <- function(summary.results, benefits.matrix, draw.labels=TRUE){
  
  tmp <- summary.results
  
  tmp$total_cost <- (tmp$total_cost / 10^6) # rescale x-axis to millions
  tmp$threshold <- round(tmp$threshold) # remove decimal points
  
  # Create plot object
  this.plot <- ggplot(tmp, aes(
    x = total_cost, 
    y = number_of_species, 
    group = threshold, 
    # linetype = factor(threshold),
    # shape = factor(threshold), 
    label = ifelse(strategies=="Baseline"," ",strategies)
  )
  ) +
    geom_step(aes(color = factor(threshold)), 
      # size = 0.8,
      # alpha = 0.6
    ) +
    geom_point(
      aes(color = factor(threshold)),
      size = 2
      ,show.legend = FALSE
    ) +
    theme_cowplot() +
    theme(legend.justification = c(1,0),
          legend.position = c(0.95, 0.05),
          legend.key.height = unit(0.6,"cm"),
          legend.key.width = unit(1, "cm"),
          legend.title = element_text(size = 12),
          legend.text = element_text(size = 12),
          plot.margin = margin(0.5, 1, 0.5, 0.5, "cm")
          # legend.title.align=0.5
    ) +scale_colour_manual(values = cols) +
    scale_y_continuous(
      # labels = function (x) floor(x), 
      breaks = min(tmp$number_of_species):length(benefits.matrix),
      limits = c(min(tmp$number_of_species), length(benefits.matrix))
    ) +
    labs(x = "Total cost (millions)", 
         y = "Number of groups secured"
         , color="Persistence\nthreshold (%)"
         # , linetype = "Persistence\nthreshold (%)"
         , shape = "Persistence\nthreshold (%)"
    )
  
  if(draw.labels){
    this.plot <- this.plot + 
      geom_text_repel(size = 4
                      , hjust = "left"
                      # ,nudge_x = 0.5,
                      # nudge_y = -0.15
                      #,xlim = c(0, max(tmp$total_cost)+5),
                      # ylim = c(-0.5, max(tmp$number_of_species)+0.5),
                      # show.legend = FALSE
                      # # , direction = "both"
      )
  }
  
  plot(this.plot)
  this.plot
}

#' Plot using custom function above
optcurve.best <- PlotOptCurve(results.best, best, draw.labels = TRUE)

#+ eval = FALSE
ggsave(paste0(figures, "/Complementarity_best.pdf"), optcurve.best, width = 180, height = 120, units = "mm")
# ggsave(paste0(figures, "/Complementarity_best.tiff"), optcurve.best, width = 120, height = 115, units = "mm", dpi = 600)


#' ### Uncertainty analysis
#' Create expected performance matrices for lowest and highest estimates
low <- perf.transposed %>%
  filter(grepl("Low", Estimate)) %>%
  mutate(Estimate = NULL) %>%
  column_to_rownames("Strategy")

low <- round(low, digits=0)

high <- perf.transposed %>%
  filter(grepl("High", Estimate)) %>%
  mutate(Estimate = NULL) %>%
  column_to_rownames("Strategy")

high <- round(high, digits=0)

write.csv(low, paste0(results, "/ExpPerform_low.csv"), row.names = FALSE) 
write.csv(high, paste0(results, "/ExpPerform_high.csv"), row.names = FALSE) 

#' Run the optimization for the most pessimistic scenario (lowest estimates) 
#' and the most optimistic scenario (highest estimates)
#+ eval = FALSE
#+ 

cols <- c("40" = "brown2", "50" = "goldenrod1", "60" = "darkolivegreen3", "70" = "darkmagenta")

results.low <- Optimize(benefits.matrix = low,
                  cost.vector = costs,
                  combo.strategies = combos
                  , thresholds = c(40.01, 50.01)
                  )

results.high <- Optimize(benefits.matrix = high,
                  cost.vector = costs,
                  combo.strategies = combos
                  , thresholds = c(60.01, 70.01)
                  ) 

write.csv(results.low, paste0(results, "/Complementarity_low.csv"), row.names = FALSE)
write.csv(results.high, paste0(results, "/Complementarity_high.csv"), row.names = FALSE)

#' Plot the benefit curves for lowest and highest estimates
#+ eval = FALSE
# Using plotting function included in the consOpt package:
# optcurve.low <- PlotResults(results.low)
# optcurve.high <- PlotResults(results.high)

# OR using the custom plot function above:
optcurve.low <- PlotOptCurve(results.low, low, draw.labels = TRUE)
optcurve.high <- PlotOptCurve(results.high, high, draw.labels = TRUE)

# Save plots as pdf or tiff files
ggsave(paste0(figures, "/Complementarity_low_4050.png"), optcurve.low, width = 180, height = 120, units = "mm")
ggsave(paste0(figures, "/Complementarity_high_6070.png"), optcurve.high, width = 180, height = 120, units = "mm")
# ggsave(paste0(figures, "/Complementarity_low.tiff"), optcurve.low, width = 120, height = 115, units = "mm", dpi = 600)
# ggsave(paste0(figures, "/Complementarity_high.tiff"), optcurve.high, width = 120, height = 115, units = "mm", dpi = 600)

```

STEP 5A: 

Recreating the Table 2 plots for color!
```{r}
######FOR POP 

##Best 
results <- here("analysis", "results","Dec042023") # where results of analysis should be saved
exp.perf <- read.csv(paste0(results, "/ExpPerform_all.csv"), header = TRUE) # list of individual strategies that make up each strategy (in columns). Should have a column for baseline and all strategies

best <- exp.perf %>% select(contains(c("Group","Best")))
high <- exp.perf %>% select(contains(c("Group","High")))
low <- exp.perf %>% select(contains(c("Group","Low")))

names(best) = gsub(pattern = "Wt.Best_", replacement = "", x = names(best))
names(high) = gsub(pattern = "Wt.High_", replacement = "", x = names(high))
names(low) = gsub(pattern = "Wt.Low_", replacement = "", x = names(low))


write.csv(best, paste0(results, "/table2_best.csv"), row.names = FALSE)
write.csv(high, paste0(results, "/table2_high.csv"), row.names = FALSE)
write.csv(low, paste0(results, "/table2_low.csv"), row.names = FALSE)


########FOR BENEFITS 
exp.benf <- read.csv(paste0(results, "/ExpBenefits.csv"), header = TRUE) # only benefits for all species groups for all 3 estimates

best <- exp.benf %>% select(contains(c("Group","Best")))
high <- exp.benf %>% select(contains(c("Group","High")))
low <- exp.benf %>% select(contains(c("Group","Low")))

names(best) = gsub(pattern = "Wt.Best_", replacement = "", x = names(best))
names(high) = gsub(pattern = "Wt.High_", replacement = "", x = names(high))
names(low) = gsub(pattern = "Wt.Low_", replacement = "", x = names(low))


write.csv(best, paste0(results, "/table2_best_bnft.csv"), row.names = FALSE)
write.csv(high, paste0(results, "/table2_high_bnft.csv"), row.names = FALSE)
write.csv(low, paste0(results, "/table2_low_bnft.csv"), row.names = FALSE)

##############Stacked barplot
results <- here("analysis", "results","Dec042023") # where results of analysis should be saved
exp.perf <- read.csv(paste0(results, "/ExpPerform_all.csv"), header = TRUE) 
best <- exp.perf %>% select(contains(c("Group","Best")))
best_bs11 <- best %>% select(contains(c("Group","Baseline","S11")))
best_bs11$Wt.Best_S11 <- best_bs11$Wt.Best_S11-best_bs11$Wt.Best_Baseline
best_bs11 <- best_bs11 %>% 
  rename(
    S11 = Wt.Best_S11,
    Baseline = Wt.Best_Baseline
    )
best_bs11 <- best_bs11%>%pivot_longer(cols = c(Baseline,S11))
best_bs11 <- best_bs11 %>% 
  rename(Strategy = name, POP = value
    )
best_bs11$Strategy <- as.factor(best_bs11$Strategy)
best_bs11$Ecological.Group<-gsub("species","",as.character(best_bs11$Ecological.Group))
best_bs11$Ecological.Group<-gsub("Artificial structure dependent","Building dependent",as.character(best_bs11$Ecological.Group))
best_bs11$Ecological.Group<-gsub("Naturalized open habitat","Nat.open habitat",as.character(best_bs11$Ecological.Group))


best_bs11$Strategy <- factor(best_bs11$Strategy, levels = c('S11','Baseline'))
plot1 <- ggplot(best_bs11, aes(fill=Strategy, y=POP, x=Ecological.Group)) + 
  geom_bar(position="stack", stat="identity")+
  theme_bw()+
  scale_fill_manual(values=c( "deepskyblue4","beige"))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  geom_hline(yintercept = 60)

#######################################stacked bar plot for all strategies+ S11 
results <- here("analysis", "results","Dec042023") # where results of analysis should be saved
exp.perf <- read.csv(paste0(results, "/ExpPerform_all.csv"), header = TRUE) 
best <- exp.perf %>% select(contains(c("Group","Best")))
best_bs115 <- best %>% select(contains(c("Group","Baseline","S11","S15")))
best_bs115$Wt.Best_S15 <- best_bs115$Wt.Best_S15-best_bs115$Wt.Best_S11 #why S15 needs to be higher than S11 
best_bs115$Wt.Best_S11 <- best_bs115$Wt.Best_S11-best_bs115$Wt.Best_Baseline
best_bs115 <- best_bs115 %>% 
  rename(
    S11 = Wt.Best_S11,
    S15 = Wt.Best_S15,
    Baseline = Wt.Best_Baseline
    )
best_bs115 <- best_bs115%>%pivot_longer(cols = c(Baseline,S11,S15))
best_bs115 <- best_bs115 %>% 
  rename(Strategy = name, POP = value
    )
best_bs115$Strategy <- as.factor(best_bs115$Strategy)
best_bs115$Ecological.Group<-gsub("species","",as.character(best_bs115$Ecological.Group))
best_bs115$Ecological.Group<-gsub("Artificial structure dependent","Building dependent",as.character(best_bs115$Ecological.Group))
best_bs115$Ecological.Group<-gsub("Naturalized open habitat","Nat.open habitat",as.character(best_bs115$Ecological.Group))


best_bs115$Strategy <- factor(best_bs115$Strategy, levels = c('S15','S11','Baseline'))
plot2 <- ggplot(best_bs115, aes(fill=Strategy, y=POP, x=Ecological.Group)) + 
  geom_bar(position="stack", stat="identity")+
  theme_bw()+
  scale_fill_manual(values=c( "lightgreen","deepskyblue4","beige"))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  geom_hline(yintercept = 60)

#######################################stacked bar plot for S11 + S14 + S5
results <- here("analysis", "results","Dec042023") # where results of analysis should be saved
exp.perf <- read.csv(paste0(results, "/ExpPerform_all.csv"), header = TRUE) 
best <- exp.perf %>% select(contains(c("Group","Best")))
best_turt <- best %>% select(contains(c("Group","Baseline","S11","S14","S5")))
best_turt$Wt.Best_S14 <- best_turt$Wt.Best_S14-best_turt$Wt.Best_S11 #why S14 needs to be higher than S11 
best_turt$Wt.Best_S5 <- best_turt$Wt.Best_S5-best_turt$Wt.Best_S11 #why S5 needs to be higher than S11 
best_turt$Wt.Best_S11 <- best_turt$Wt.Best_S11-best_turt$Wt.Best_Baseline
best_turt <- best_turt %>% 
  rename(
    S11 = Wt.Best_S11,
    S14 = Wt.Best_S14,
    S5 = Wt.Best_S5,
    Baseline = Wt.Best_Baseline
    )
best_turt <- best_turt%>%pivot_longer(cols = c(Baseline,S11,S14,S5))
best_turt <- best_turt %>% 
  rename(Strategy = name, POP = value
    )

####if less than 0, become 0, otherwise graph would look weird 
best_turt$POP[best_turt$POP<0] <- 0


best_turt$Strategy <- as.factor(best_turt$Strategy)
best_turt$Ecological.Group<-gsub("species","",as.character(best_turt$Ecological.Group))
best_turt$Ecological.Group<-gsub("Artificial structure dependent","Building dependent",as.character(best_turt$Ecological.Group))
best_turt$Ecological.Group<-gsub("Naturalized open habitat","Nat.open habitat",as.character(best_turt$Ecological.Group))


best_turt$Strategy <- factor(best_turt$Strategy, levels = c('S14','S5','S11','Baseline'))
plot3<- ggplot(best_turt, aes(fill=Strategy, y=POP, x=Ecological.Group)) + 
  geom_bar(position="stack", stat="identity")+
  theme_bw()+
  scale_fill_manual(values=c( "maroon","orange","deepskyblue4","beige"))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  geom_hline(yintercept = 60)

#####Just baseline
baseline <- best_turt%>%filter(Strategy=="Baseline")
plot4 <- ggplot(baseline,aes(y=POP, x=Ecological.Group)) + 
  geom_bar(stat="identity", fill="beige")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  geom_hline(yintercept = 60)
```


Step 6: Uncertainty analysis (Apr-13)

 Generates `MC` random samples from range of uncertainty in benefit and cost 
 estimates, calculates cost-effectiveness (CE) scores for each rep, and 
 creates boxplots and ridgeplots to visualize variation in CE scores and ranks 
 resulting from uncertainty.  
   
 Needs:  
 1) **Estimates_tidy.csv** from *import.R*,  
 2) a .csv file **EcolGroupsList.csv** with ecological groups in columns and 
 the list of species for each group in rows,  
 3) a .csv file **SpecialCases.csv** listing only the estimates (from which
 expert, and for which ecol group and strategy) that require different
 weighting, along with the number of species in that group that the estimate
 is based on,  
 4) **Benefits_total.rds** from *calculateCE.R*, and  
 5) a table **CostFeas.csv** of strategy costs and feasibility.  
 
```{r}

#+ warning = FALSE, message = FALSE
# Load packages
library(tidyverse)
library(mc2d)
library(cowplot)
library(ggridges)
library(viridis)
library(here)

# Set parameters
a <- 10^6 # scaling to get cost and benefits in roughly the same order of magnitude
MC <- 1000 # number of iterations (reps) for uncertainty analysis
u <- 0.3 # % variation (in costs) from the best estimate

# Specify paths to subfolders within current working directory
input <- here("analysis", "data", "raw") # where .csv files of benefit estimates are saved
derived <- here("analysis", "data","June282023") # where compiled data tables should be saved
results <- here("analysis", "results","June282023") # where results of analysis should be saved
figures <- here("analysis", "figures","June282023")
code <- here("analysis", "code")

# Load custom functions for calculating and weighting individual benefit estimates
source(paste0(code, "/ptmfunc.R"))

#' Import data
#+ warning = FALSE, message = FALSE
# Get cost & feasibility table
costfeas <- read.csv(paste0(results, "/CostFeas.csv"))
names(costfeas)[2] <- "Cost" # for ON PTM only - col 2 is the cost with 0% discount rate. Col 4 = 2%, Col5 = 3.5%
names(costfeas)[3] <- "Avg.Feas" # for ON PTM only
costfeas$Strategy <- as_factor(costfeas$Strategy)
costfeas <- costfeas[-1,] # Remove baseline values

# Get table of individual expert estimates for sampling
long <- read.csv(paste0(derived, "/Estimates_tidy.csv"))

wide <- long %>%
  pivot_wider(names_from = Estimate, values_from = Value)
wide$Expert <- as_factor(wide$Expert)
wide$Ecological.Group <- as_factor(wide$Ecological.Group)
wide$Strategy <- as_factor(wide$Strategy)

# Get number of species in each group and number of species scored by each expert for each strategy
grplist <- read_csv(paste0(input, "/EcolGroupsList.csv")) # use read_csv() to keep spaces in column names
sppwts <- sum_spp(grplist)

# Get the number of species scored by each expert for each strategy
spcases <- read_csv(paste0(derived, "/SpecialCases.csv")) 
names(spcases)[which(str_detect(names(spcases), "Group") == 1)] <- "Ecological.Group"  

spcases$Strategy <- factor(spcases$Strategy, levels = levels(wide$Strategy))
spcases$Expert <- factor(spcases$Expert, levels = levels(wide$Expert))
spcases$Ecological.Group<- factor(spcases$Ecological.Group, 
                                  levels = levels(wide$Ecological.Group))

# Get (Best Guess) Benefits data from calculateCE.R
bestben.sum <- readRDS(paste0(results, "/Benefits_total.rds")) 

#' Load custom functions for plotting CE scores and ranks
boxplot.uncrtn <- function(scoredata) {
  CEscores <- scoredata %>%
    pivot_longer(-Strategy, names_to = "Iteration", values_to = "CE") %>%
    mutate(Strategy = factor(Strategy, levels = unique(scoredata$Strategy)))
  temp.plot <- ggplot(CEscores, 
                      aes(x = Strategy, y = CE)
                      ) +
    geom_boxplot(
      lwd = 0.3 #lwd changes line width
      , fatten = 1 # thickness of median line; default is 2
      , outlier.size = 1 # size of outlier point
      ) + 
    theme_cowplot() +  
    theme(
      axis.text = element_text(size = 10)
      , axis.line = element_line(size = 1)
      ) +
    scale_x_discrete(name = "Management strategies"
                     , breaks = levels(CEscores$Strategy)
                     , labels = levels(CEscores$Strategy)
                     ) +
    labs(x = "Management strategies"
         , y = "Cost-effectiveness score"
         ) #+
    # ylim(0, 200) 
}

rankfreq <- function(rankdata) {
  
  CEranks <- rankdata %>%
    pivot_longer(-Strategy, names_to = "Iteration", values_to = "CE_rank") %>%
    mutate(Strategy = factor(Strategy, levels = unique(rankdata$Strategy)))
  
  count_ranks <- xyTable(CEranks$Strategy, CEranks$CE_rank)
  rank_table <- data.frame(count_ranks$x, count_ranks$y, count_ranks$number)
  rank_table_sort <- as_tibble(rank_table)
  names(rank_table_sort) <- c("Strategy", "CE_rank", "Count")
  rank_table_sort <- group_by(rank_table_sort, Strategy) %>%
    filter(Count == max(Count)) %>%
    arrange(desc(CE_rank))
  
  strat.order <- rank_table_sort$Strategy
  stgyorder <- paste0("S", unique(strat.order))
  
  temp.plot.r <- ggplot(CEranks, 
                        aes(y = factor(Strategy, levels = stgyorder)
                            , x = CE_rank
                            , fill = factor(Strategy, levels = stgyorder)
                            )
                        ) +
    geom_density_ridges(stat = "binline", bins = length(stgyorder), scale = 0.9, draw_baseline = FALSE) +
    theme_ridges(grid = TRUE, center_axis_labels = TRUE) +
    theme(
      legend.position = "none"
      , panel.spacing = unit(0.1, "lines")
      , strip.text = element_text(size = 8)
      , axis.ticks = element_blank()
      , axis.line = element_line(size = 0.3)
      , panel.grid = element_line(size = 0.3)
      ) +
    scale_fill_viridis(option = "plasma", discrete = TRUE) +
    labs(x = "Cost-effectiveness rank"
         , y = "Management strategies"
         ) +
    scale_x_continuous(breaks = c(1:length(stgyorder))
                       , labels = c(1:length(stgyorder))
                       # , limits = c(0, max(rank_table$count_ranks.x)+1)
                       )
}

#' ## Uncertainty analysis for cost-effectiveness (CE) scores
#' ### Uncertainty in Benefit estimates
#' Generate MC samples and calculate Expected Benefits and CE scores for each rep
#+ warning = FALSE, message = FALSE
samples_ben <- matrix(nrow = nrow(wide),ncol = MC)
MC.CEScore_ben <- list()

set.seed(1565)

for(it in 1:MC){
  
  # Sample benefit values from distribution provided by each expert
  samples_ben[,it] <- rpert(nrow(wide),
                        min = wide$Low,
                        mode = wide$Best,
                        max = wide$High, shape = 4)
  
  temp <- cbind(wide[,1:3], samples_ben[,it]) 
  names(temp)[4] <- "MC.Sample"
  
  # Calculate benefit for each MC sample set
  temp.wide <- pivot_wider(temp, names_from = Strategy, values_from = MC.Sample)
  temp.strat <- select(temp.wide, -Expert, -Ecological.Group, -Baseline) 
  
  temp.ben <- temp.strat - temp.wide$Baseline
  # temp.ben[temp.ben<0] <- 0 # replace negative benefit values with 0 (assume strategy has no benefit)
  temp.ben <- cbind(temp.wide[,1:2], temp.ben) 
  
  # Determine weights to assign based on number of species scored by each expert
  temp.long <- pivot_longer(temp.ben, -c(1:2), names_to = "Strategy", values_to = "Value") %>%
    mutate(Estimate = rep(c("Sample"), times = nrow(.)), .before = Value)
  temp.long$Strategy <- factor(temp.long$Strategy, levels = levels(wide$Strategy))
  
  temp.joined <- wt_species(temp.long, sppwts, spcases) # custom function
  
  # Calculate weighted average based on number of species scored by each expert
  temp.agg <- aggregate(temp.joined$Wt.Avg, 
                        by = list(Ecological.Group = temp.joined$Ecological.Group, 
                                  Strategy = temp.joined$Strategy), 
                        FUN = sum, na.rm = TRUE)
  
  # Weight (multiply) the averaged benefit by the number of species in group
  wt.temp.agg <- left_join(temp.agg, sppwts, by = "Ecological.Group") %>%
    mutate(Wt.Benefit = x*numspp)  # 'x' is the weighted average from above
  
  # Calculate (sum) total benefit of each strategy across all ecological groups
  sum.ben <- aggregate(wt.temp.agg$Wt.Benefit, 
                       by = list(Strategy = wt.temp.agg$Strategy),
                       FUN = sum, na.rm = TRUE)
  names(sum.ben)[2] <- "Benefit"
  
  # Calculate cost-effectiveness
  strat.est <- left_join(sum.ben, costfeas, by="Strategy") %>%
    mutate(sc.Cost = Cost/a, # scale costs to get reasonable values
           Exp.Benefit = Benefit * Avg.Feas, # calculate expected benefit
           CE = (Benefit * Avg.Feas)/sc.Cost) # calculate cost-effectiveness score
  
  # Rank strategies by CE Score, Expected Benefit, and Cost
  CE_Score <- select(strat.est, c("Strategy", "Benefit", "Cost", "Avg.Feas", "Exp.Benefit","CE")) %>%
    mutate(CE_rank = rank(-CE), 
           ExpBenefit_rank = rank(-Exp.Benefit), 
           Cost_rank = rank(Cost))
  
  MC.CEScore_ben[[it]] <- CE_Score # save to list for plotting
  
} #end for

#' Compile results from all reps
MC.CETable_ben <- lapply(MC.CEScore_ben, "[", 1:length(strat.est$Strategy), "CE") 
MC.Results_ben <- matrix(unlist(MC.CETable_ben), ncol = MC, byrow = FALSE)
MC.Results_ben <- data.frame(strat.est$Strategy[1:length(strat.est$Strategy)], MC.Results_ben)
names(MC.Results_ben)[1] <- "Strategy"

MC.CERank_ben <- lapply(MC.CEScore_ben, "[", 1:length(strat.est$Strategy), "CE_rank")
MC.Ranks_ben <- matrix(unlist(MC.CERank_ben), ncol = MC, byrow = FALSE)
MC.Ranks_ben <- data.frame(strat.est$Strategy[1:length(strat.est$Strategy)], MC.Ranks_ben)
names(MC.Ranks_ben)[1] <- "Strategy"

MC.Samples_ben <- data.frame(wide[,1:3], samples_ben)

write_csv(MC.Results_ben, paste0(results, "/Uncertainty_CEScores_benefits.csv"))
write_csv(MC.Ranks_ben, paste0(results, "/Uncertainty_CERanks_benefits.csv"))
write_csv(MC.Samples_ben, paste0(derived, "/Uncertainty_SampledData_benefits.csv"))

#' Plot CE scores and ranks for benefit uncertainty
# Boxplots of CE scores, showing median and interquartile range of CE scores
# from each rep.
ben.boxplot <- boxplot.uncrtn(MC.Results_ben)

ggsave(filename=paste0(figures, "/Uncrtn_Ben_", MC, "reps_Scores.png", sep = ""), 
       ben.boxplot, width = 180, height = 180, units = "mm")
# ggsave(filename=paste0(figures, "/Uncrtn_Ben_", MC, "reps_Scores.tiff", sep = ""), 
#        ben.boxplot, width = 180, height = 180, units = "mm", dpi = 600)

# Ridgeplots of CE ranks, showing frequency (y-axis) that each strategy (rows) 
# is assigned a given CE rank (x-axis) based on its CE score from each rep.
ben.ranks <- rankfreq(MC.Ranks_ben)

ggsave(filename=paste0(figures, "/Uncrtn_Ben_", MC, "reps_Ranks.png", sep = ""), 
       ben.ranks, width = 180, height = 180, units = "mm")
# ggsave(filename=paste0(figures, "/Uncrtn_Ben_", MC, "reps_Ranks.tiff", sep = ""), 
#        ben.ranks, width = 180, height = 180, units = "mm", dpi = 600)

#' Sample plots
# ben.boxplot
# ben.ranks

#' ### Uncertainty in cost estimates
#+ warning = FALSE, message = FALSE
# Get range of uncertainty in cost estimates
minidx <- grep("min.cost", names(costfeas), ignore.case = TRUE)
if (is_empty(minidx) == 0) {
  min.Cost <- costfeas[,minidx]
  best.Cost <- costfeas[,grep("best.cost", names(costfeas), ignore.case = TRUE)]
} else {
  min.Cost <- costfeas$Cost * (1-u)
  best.Cost <- costfeas$Cost
}

maxidx <- grep("max.cost", names(costfeas), ignore.case = TRUE)
if (is_empty(maxidx) == 0) {
  max.Cost <- costfeas[,maxidx]
} else {
  max.Cost <- costfeas$Cost * (1+u)
}

#' Generate MC samples of Cost and calculate CE for each rep
#+ warning = FALSE, message = FALSE
samples <- matrix(nrow = nrow(costfeas),ncol = MC)
MC.CEScore_cost <- list()

set.seed(3279)

for (it in 1:MC) {
  
  # sample cost values
  samples[,it] <- rpert(nrow(costfeas),
                        min = min.Cost,
                        mode = best.Cost,
                        max = max.Cost, shape = 4)
  costfeas.mc <- costfeas %>%
    mutate(Sampled.Cost = samples[,it])
  
  # Join with benefits table (need to get this from the CE script, probably bestben.sum) and calculate cost-effectiveness
  strat.est <- full_join(bestben.sum, costfeas.mc , by = "Strategy") %>%
    mutate(Sc.Cost = Sampled.Cost/a, # scale costs to get reasonable values
           Exp.Benefit = Benefit * Avg.Feas, # weight benefits
           CE = (Benefit * Avg.Feas)/Sc.Cost) # calculate cost-effectiveness scores
  
  # Rank strategies by (weighted)Benefit, Cost, and CE score
  CE_Score <- select(strat.est, c("Strategy", "Benefit", "Sampled.Cost", "Avg.Feas", "Exp.Benefit","CE")) %>%
    mutate(CE_rank = rank(-CE),
           ExpBenefit_rank = rank(-Exp.Benefit),
           Cost_rank = rank(Sampled.Cost))
  
  MC.CEScore_cost[[it]] <- CE_Score
  
} # end for

#' Compile results from all reps
MC.CETable_cost <- lapply(MC.CEScore_cost, "[", 1:length(strat.est$Strategy), "CE")
MC.Results_cost <- matrix(unlist(MC.CETable_cost), ncol = MC, byrow = FALSE)
MC.Results_cost <- data.frame(strat.est$Strategy, MC.Results_cost)
names(MC.Results_cost)[1] <- "Strategy"

MC.CERank_cost <- lapply(MC.CEScore_cost, "[", 1:length(strat.est$Strategy), "CE_rank")
MC.Ranks_cost <- matrix(unlist(MC.CERank_cost), ncol = MC, byrow = FALSE)
MC.Ranks_cost <- data.frame(strat.est$Strategy, MC.Ranks_cost)
names(MC.Ranks_cost)[1] <- "Strategy"

MC.Samples_cost <- data.frame(costfeas$Strategy, samples)

write_csv(MC.Results_cost, paste0(results, "/Uncertainty_CEScores_cost.csv"))
write_csv(MC.Ranks_cost, paste0(results, "/Uncertainty_CERanks_cost.csv"))
write_csv(MC.Samples_cost, paste0(derived, "/Uncertainty_SampledData_cost.csv"))

#' Plot CE scores and ranks for cost uncertainty
# Boxplots of CE scores
cost.boxplot <- boxplot.uncrtn(MC.Results_cost)

ggsave(filename = paste0(figures, "/Uncrtn_Cost_", MC, "reps_Scores.png", sep = ""), 
       cost.boxplot, width = 180, height = 115, units = "mm")
# ggsave(filename=paste0(figures, "/Uncrtn_Cost_", MC, "reps_Scores.tiff", sep = ""), 
#        cost.boxplot, width = 180, height = 115, units = "mm", dpi = 600)

# Ridgeplots of CE ranks, showing frequency (y-axis) that each strategy (rows) 
# is assigned a given CE rank (x-axis) based on its CE score from each rep.
cost.ranks <- rankfreq(MC.Ranks_cost)

ggsave(filename=paste0(figures, "/Uncrtn_Cost_", MC, "reps_Ranks.png", sep = ""), 
       cost.ranks, width = 180, height = 180, units = "mm")
# ggsave(filename=paste0(figures, "/Uncrtn_Cost_", MC, "reps_Ranks.tiff", sep = ""), 
#        cost.ranks, width = 180, height = 180, units = "mm", dpi = 600)

#' Sample plots
# cost.boxplot
# cost.ranks
```
